{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework-02-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "max_cell_id": 35
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 1,
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Введение в глубинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Домашнее задание 2. Классификация изображений. Сверточныенейронные сети.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 07.11.2021\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 28.11.2021\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 02.12.2021\n",
        "\n",
        "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 8.5, а если сдать перед самым жестким дедлайном, то ваш максимум — 5.22 балла.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=0).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 3,
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "## Задание 1. (Максимум 10 баллов + 5 бонусных баллов)\n",
        "\n",
        "__Необходимо выполнить любое из двух заданий (на выбор)__\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров). Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 45 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 4,
        "id": "LKcSNj4tlRVK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "# You may add any imports you need"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llye3TAn9YOe"
      },
      "source": [
        "!wget https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=1 -O dataset.zip && unzip -q dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSqSsFg4lRVN"
      },
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform):\n",
        "        # YOUR CODE\n",
        "        pass\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # YOUR CODE\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        # YOUR CODE\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 5,
        "id": "QEdDQtHdlRVO"
      },
      "source": [
        "train_transform = None\n",
        "val_transform = None\n",
        "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
        "\n",
        "train_dataset = MyDataset(\"./dataset/dataset/train\", transform=train_transform)\n",
        "val_dataset = MyDataset(\"./dataset/dataset/val\", transform=val_transform)\n",
        "# REPLACE ./dataset/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n",
        "# OR USE torchvision.datasets.ImageFolder INSTEAD OF MyDataset\n",
        "\n",
        "train_dataloader = # TRAIN DATALOADER WHICH YOU CONSTRUCT\n",
        "val_dataloader = # VAL DATALOADER WHICH YOU CONSTRUCT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 6,
        "id": "mrg4Yj0VlRVP"
      },
      "source": [
        "# Just very simple sanity checks\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[1][1], int)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 7,
        "id": "yYG2-Cq8lRVQ"
      },
      "source": [
        "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
        "    model.train()\n",
        "    # YOUR CODE\n",
        "    # TRAIN YOUR MODEL HERE\n",
        "    pass\n",
        "\n",
        "\n",
        "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
        "    model.eval()\n",
        "    # YOUR CODE\n",
        "    # PREDICT FOR EVERY ELEMENT OF THE VAL DATALOADER AND RETURN CORRESPONDING LISTS\n",
        "    return losses, predicted_classes, true_classes\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "        # YOUR CODE\n",
        "        # Train, evaluate, print accuracy, make a step of scheduler or whatever you want...\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 8,
        "id": "JXFJ6oS8lRVX",
        "scrolled": true
      },
      "source": [
        "model = # THE MODEL THAT YOU CHOOSE\n",
        "optimizer = # YOUR OPTIMIZER\n",
        "criterion = # LOSS THAT YOU OPTIMIZE (SHOLD BE CROSS ENTROPY OR SMTH ELSE)\n",
        "scheduler = # LR SCHEDULE THAT YOU PROBABLY CHOOSE\n",
        "n_epochs = # NUMBER OF EPOCHS\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 9,
        "id": "CesoOl6BlRVY"
      },
      "source": [
        "Простой тест на проверку правильности написанного кода"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 10,
        "id": "B_LB2jn6lRVY"
      },
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(predicted_labels, true_labels)\n",
        "print(\"tests passed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 11,
        "id": "tS-LLiXUlRVY"
      },
      "source": [
        "Запустить обучение можно в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 12,
        "id": "ECIzZ_RYlRVZ"
      },
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 13,
        "id": "FmR-elhJlRVZ"
      },
      "source": [
        "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 14,
        "id": "3TGH0EFalRVb"
      },
      "source": [
        "#all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "#assert len(predicted_labels) == len(val_dataset)\n",
        "#accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "accuracy = 0.42\n",
        "print(f'Оценка за это задание составит {np.clip(10 * accuracy / 0.44, 0, 10):.2f} баллов,'\\\n",
        "      f' если вы делали часть 1, и {np.clip(10 * (accuracy - 0.5) / 0.34, 0, 10):.2f} баллов,'\\\n",
        "      f' если вы делали часть 2.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 15,
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "## Задание 2 (0 баллов, но при невыполнении максимум за все задание — 0 баллов)\n",
        "\n",
        "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYSNt0dcPVpD"
      },
      "source": [
        "# YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}