{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c368f2",
   "metadata": {},
   "source": [
    "# Глубинное обучение 1 / Введение в глубинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 3: RNN и языковые модели \n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{\\text{penalty}} = M_{\\text{full}} \\cdot 0.85^{t/1440}$, где $M_{\\text{full}}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 12.75, а если сдать через четыре дня после мягкого дедлайна, то ваш максимум — 7.83 балла.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит обучить рекуррентную нейронную сеть для задачи генерации текстов. В качестве данных возьмем набор из 120 тысяч анекдотов (всех категорий от А до Я включительно). Его вы можете найти в архиве `jokes.txt.zip`, который доступен по [ссылке](https://disk.yandex.com/d/fjt5xICH-ukEEA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daae037",
   "metadata": {},
   "source": [
    "## Задание 1: Dataset (1 балл)\n",
    "\n",
    "В этом задании мы будет пользоваться библиотекой [sentencepiece](https://github.com/google/sentencepiece), которая поддерживает разные форматы токенизации текстов, в том числе BPE, который мы и будем использовать. Реализуйте недостающие фрагменты кода в классе `TextDataset` в файле `dataset.py`. Датасет обучает sentencepiece токенизатор, токенизирует тексты, превращает токены в индексы и паддит до одной и той же длины (параметр `max_length`). Не забудьте, что для генерации текстов нам будут нужны специальные токены начала и конца последовательности, соответственно `BOS` и `EOS`. Существуют еще два специальных токена &mdash; паддинг `PAD` и токен `UNK`, заменяющий out-of-vocabulary токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataset import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81630e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TextDataset(data_file='jokes.txt', train=True, sp_model_prefix='bpe')\n",
    "valid_set = TextDataset(data_file='jokes.txt', train=False, sp_model_prefix='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27555b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код должен проходить тесты\n",
    "assert len(train_set) + len(valid_set) == 120759\n",
    "\n",
    "for _ in range(5):\n",
    "    for dataset in (train_set, valid_set):\n",
    "        indices, length = dataset[np.random.randint(len(dataset))]\n",
    "        assert indices.shape == (dataset.max_length, )\n",
    "        assert indices[0].item() == dataset.bos_id\n",
    "        assert (indices == dataset.eos_id).sum().item() == 1\n",
    "\n",
    "        eos_pos = indices.tolist().index(dataset.eos_id)\n",
    "        assert torch.all(indices[eos_pos + 1:] == dataset.pad_id)\n",
    "        assert (indices != dataset.pad_id).sum() == length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db087d5",
   "metadata": {},
   "source": [
    "## Задание 2 Language model (3.5 балла)\n",
    "\n",
    "Реализуйте класс `LanguageModel` из файла `model.py`. Мы будем генерировать текст с помощью языковой модели &mdash; это авторегрессионная вероятностная модель, которая предсказывает распределение следующего токена при условии предыдущих:\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, x_3, \\dots, x_T) = p(x_1) \\cdot p(x_2 | x_1) \\cdot p(x_3|x_1, x_2) \\, \\cdot \\, \\dots \\, \\cdot \\, p(x_T|x_1, \\dots, x_{T-1})\n",
    "$$\n",
    "\n",
    "Мы будем реализовывать ее с помощью рекуррентной нейронной сети. Ваш код должен поддерживать возможность работать как с оригинальной [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN), так и c [LSTM](https://bitly.com/98K8eH). На каждом временном шаге модель возвращает логиты вероятностей для следующего токена. Модель будет работать в двух режимах (не путать с `.train()` и `.eval()`):\n",
    "\n",
    "- В режиме обучения (метод `forward`) модель принимает настоящие последовательности из датасета и их длины. На каждом временном шаге возвращаются логиты вероятностей следующего токена, что позволяет считать лосс, обучаться на трейне и валидироваться на валидации.\n",
    "\n",
    "- В режиме генерации (инференса, метод `inference`) модель принимает некоторый префикс (возможно пустой), с которого начинать генерацию, и продолжает его. Для этого на каждом шаге генерируются новые логиты, семплируется новый токен (из распределения, заданного логитами), и процесс продолжается, пока не будет сгенерирован токен `EOS` или не будет достигнуто ограничение на длину последовательности. **Обратите внимание**, что вам не нужно прогонять всю последовательность заново через RNN после каждого нового токена, это приведет к квадратичной сложности по длине последовательности. Вам достаточно обновлять скрытое состояние, подавая на вход новый сгенерированный токен и предыдущее скрытое состояние. Кроме того, чтобы получить больше контроля над генерацией, вводится параметр температуры `temp`. Перед семплированием нужно разделить на него логиты, полученные моделью. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99427388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199406f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код должен проходить тесты\n",
    "for bs in [1, 4, 16, 64, 256]:\n",
    "    indices = torch.randint(high=train_set.vocab_size, size=(bs, train_set.max_length))\n",
    "    lengths = torch.randint(low=1, high=train_set.max_length + 1, size=(bs, ))\n",
    "    logits = model(indices, lengths)\n",
    "    assert logits.shape == (bs, lengths.max(), train_set.vocab_size)\n",
    "\n",
    "for prefix in ['', 'купил мужик шляпу,', 'сел медведь в машину и', 'подумал штирлиц']:\n",
    "    generated = model.inference(prefix, temp=np.random.uniform(0.1, 10))\n",
    "    assert type(generated) == str\n",
    "    assert generated.startswith(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eacf83",
   "metadata": {},
   "source": [
    "## Задание 3: Training (2 балла)\n",
    "\n",
    "Всё, что нам осталось &mdash; реализовать цикл обучения. Заполните пропуски в файле `train.py`. Не забудьте, что мы учим модель предсказывать вероятность следующего, а не текущего токена. Также рекомендуется обрезать батч индексов по самой длинной последовательности, чтобы не гонять паддинги вхолостую. Для оценки качества генерации будем использовать метрику [perplexity](https://towardsdatascience.com/perplexity-in-language-models-87a196019a94). Реализуйте ее подсчет в функции `plot_losses` (да, для этого достаточно только значения лосса).\n",
    "\n",
    "Обучите модель, используя ванильную RNN в качестве рекуррентного слоя. Сохраните чекпойнт обученной модели, он нам еще пригодится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ab7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dad5e1",
   "metadata": {},
   "source": [
    "## Задание 4: LSTM (0.5 балла)\n",
    "\n",
    "Обучите аналогичную модель, но с LSTM в качестве рекуррентного слоя. Сравните модели по метрикам и генерации. Не забывайте про чекпойнты!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23819c",
   "metadata": {},
   "source": [
    "## Задание 5: Sampling temperature (0.5 балла)\n",
    "\n",
    "Поэкспериментируйте, как результат генерации зависит от параметра температуры. Попробуйте генерацию с разными префиксами. Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3967c7",
   "metadata": {},
   "source": [
    "## Задание 5: Tokenizers (1 балл)\n",
    "\n",
    "До сих пор мы использовали BPE токенизатор с относительно небольшим числом токенов (2000 по умолчанию). Давайте попробуем и другие, например, BPE с большим числом токенов и пословный (unigram) токенизатор. Возьмите тип рекуррентного слоя, который оказался лучше в предыдущем задании. Обучите модели на таких токенизаторах и сравните их генерацию. Не забывайте сохранять чекпойнты. Правильно ли сравнивать между собой получившиеся модели по значению perplexity? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc550928",
   "metadata": {},
   "source": [
    "## Задание 6. Latent Semantic Analysis (2 балла)\n",
    "\n",
    "Попробуем другой подход к оцениванию качества генерации, основанный на [Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis). Реализуйте следующую метрику и сравните по ней модели, обученные с разными токенизаторами:\n",
    "\n",
    "1. Генерируем обученной моделью выборку текстов, совпадающую по размеру с валидационной выборкой.\n",
    "2. Объединяем две выборки текстов (валидационную и сгенерированную) в один корпус. Обратите внимание, что наша токенизация в общем случае необратима, поэтому для чистоты эксперимента нужно закодировать и декодировать валидационную выборку.\n",
    "3. Генерируем tf-idf матрицу для полученного корпуса.\n",
    "4. Понижаем размерность матрицы с помощью [SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html).\n",
    "5. Теперь у нас есть векторы, описывающие валидационные и сгенерированные тексты, лежащие в одном пространстве. Для каждого вектора, отвечающего сгенерированному тексту, найдем наибольший cosine similarity между ним и вектором валидационного текста. Усредним такие similarity по всем сгенерированным текстам и получим число, характеризующее похожесть сгенерированной выборки на валидационную.\n",
    "\n",
    "Какие плюсы и минусы есть у описанной метрики?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e632af",
   "metadata": {},
   "source": [
    "## Задание 7. Visualization (1 балл)\n",
    "\n",
    "В прошлом пункте мы получили векторы, описывающие валидационные и сгенерированные тексты. Попробуем визуализировать их. Примените [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) к этим векторам и нарисуйте scatter-plot с получившимися двумерными представлениями. Точки, соответствующие валидационным и сгенерированным текстам, должны быть разного цвета. Визуализируйте таким образом все три модели для разных токенизаторов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aada1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9cba5",
   "metadata": {},
   "source": [
    "## Задание 8. ruGPT perplexity (3.5 балла)\n",
    "\n",
    "Подход Latent Semantic Analysis, как и многие другие классические методы, заметно уступает нейросетевым алгоритмам анализа текстов. Вернемся к оцениванию качества генерации с помощью perplexity, для этого возьмем большую и хорошо обученную языковую модель, которая училась на огромном корпусе русских текстов. Считается, что большие языковые модели хорошо выучивают естественный язык, потому с их помощью мы сможем оценивать качество наших маленьких моделей для генерации анекдотов. Для этого мы воспользуемся сервисом [HuggingFace](https://huggingface.co/), который содержит огромное число обученных моделей для самых разных задач. Изучите и реализуйте, [подсчет perplexity](https://huggingface.co/docs/transformers/perplexity), с использованием обученной языковой модели. В качестве модели возьмите [ruGPT3-small](https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2). Сгенерируйте синтетические выборки тремя моделями, обученными выше (можете взять выборки из задания 6), и сравните их по perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c5d3dc",
   "metadata": {},
   "source": [
    "## Бонус (0.1 балл)\n",
    "\n",
    "Покажите лучший анекдот, который удалось сгенерировать вашей модели. Если проверяющий найдет его смешным, то поставит 0.1 балла."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
